{"cells":[{"cell_type":"code","execution_count":4,"id":"cf7c0862-b1b0-4120-a176-a0d223495f7f","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\vishwas.balkundi\\miniforge3\\envs\\myenv2\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","c:\\Users\\vishwas.balkundi\\miniforge3\\envs\\myenv2\\Lib\\site-packages\\torchdata\\datapipes\\__init__.py:18: UserWarning: \n","################################################################################\n","WARNING!\n","The 'datapipes', 'dataloader2' modules are deprecated and will be removed in a\n","future torchdata release! Please see https://github.com/pytorch/data/issues/1196\n","to learn more and leave feedback.\n","################################################################################\n","\n","  deprecation_warning()\n"]}],"source":["import pandas as pd\n","from torch.utils.data import Dataset, DataLoader\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","from torchtext.datasets import Multi30k\n","from typing import Iterable, List\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import DataLoader\n","from torchdata.datapipes.iter import IterableWrapper, Mapper\n","import torchtext\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","import numpy as np\n","import random"]},{"cell_type":"code","execution_count":5,"id":"4bd14219-34bc-4b00-b6a9-17a54ba8ccdc","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['You are awesome!', 'It is our choices, Harry, that show what we truly are, far more than our abilities.']\n","['Soon we must all face the choice between what is right and what is easy.', \"If you want to know what a man's like, take a good look at how he treats his inferiors, not his equals.\"]\n","['Youth can not know how age thinks and feels. But old men are guilty if they forget what it was to be young.', \"Fame's a fickle friend, Harry.\"]\n"]}],"source":["sentences = [\n","    \"If you want to know what a man's like, take a good look at how he treats his inferiors, not his equals.\",\n","    \"Fame's a fickle friend, Harry.\",\n","    \"It is our choices, Harry, that show what we truly are, far more than our abilities.\",\n","    \"Soon we must all face the choice between what is right and what is easy.\",\n","    \"Youth can not know how age thinks and feels. But old men are guilty if they forget what it was to be young.\",\n","    \"You are awesome!\"\n","]\n","\n","# Define a custom dataset\n","class CustomDataset(Dataset):\n","    def __init__(self, sentences):\n","        self.sentences = sentences\n","\n","    def __len__(self):\n","        return len(self.sentences)\n","\n","    def __getitem__(self, idx):\n","        return self.sentences[idx]\n","\n","# Create an instance of your custom dataset\n","custom_dataset = CustomDataset(sentences)\n","\n","# Define batch size\n","batch_size = 2\n","\n","# Create a DataLoader\n","dataloader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=True)\n","\n","# Iterate through the DataLoader\n","for batch in dataloader:\n","    print(batch)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["<torch.utils.data.dataloader.DataLoader at 0x25652b38320>"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["dataloader"]},{"cell_type":"code","execution_count":73,"id":"171d6f95-efc9-4921-8847-edeac28c8870","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["6lines [00:00, 5824.07lines/s]"]},{"name":"stdout","output_type":"stream","text":["Custom Dataset Length: 6\n","Sample Items:\n","Item 1: tensor([13, 21, 65, 19, 15,  4,  5, 49,  8, 18, 47,  2, 57,  5, 43, 48, 26, 12,\n","        45, 63, 11, 46,  2, 16, 11, 35,  3])\n","Item 2: tensor([37,  8, 18,  5, 40, 42,  2, 10,  3])\n","Item 3: tensor([14,  7, 17, 33,  2, 10,  2, 59, 55,  4, 20, 64,  6,  2, 38, 51, 58, 17,\n","        23,  3])\n","Item 4: tensor([56, 20, 52, 25, 36, 60, 32, 29,  4,  7, 54,  9,  4,  7, 34,  3])\n","Item 5: tensor([68, 31, 16, 15, 12, 24, 62,  9, 39,  3, 30, 53, 50,  6, 44, 13, 61, 41,\n","         4, 14, 66, 19, 28, 67,  3])\n","Item 6: tensor([21,  6, 27, 22])\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["sentences = [\n","    \"If you want to know what a man's like, take a good look at how he treats his inferiors, not his equals.\",\n","    \"Fame's a fickle friend, Harry.\",\n","    \"It is our choices, Harry, that show what we truly are, far more than our abilities.\",\n","    \"Soon we must all face the choice between what is right and what is easy.\",\n","    \"Youth can not know how age thinks and feels. But old men are guilty if they forget what it was to be young.\",\n","    \"You are awesome!\"\n","]\n","\n","# Define a custom data set\n","class CustomDataset(Dataset):\n","    def __init__(self, sentences, tokenizer, vocab):\n","        self.sentences = sentences\n","        self.tokenizer = tokenizer\n","        self.vocab = vocab\n","\n","    def __len__(self):\n","        return len(self.sentences)\n","\n","    def __getitem__(self, idx):\n","        tokens = self.tokenizer(self.sentences[idx])\n","        # Convert tokens to tensor indices using vocab\n","        tensor_indices = [self.vocab[token] for token in tokens]\n","        return torch.tensor(tensor_indices)\n","\n","# Tokenizer\n","tokenizer = get_tokenizer(\"basic_english\")\n","\n","# Build vocabulary\n","vocab = build_vocab_from_iterator(map(tokenizer, sentences))\n","\n","# Create an instance of your custom data set\n","custom_dataset = CustomDataset(sentences, tokenizer, vocab)\n","\n","print(\"Custom Dataset Length:\", len(custom_dataset))\n","print(\"Sample Items:\")\n","for i in range(6):\n","    sample_item = custom_dataset[i]\n","    print(f\"Item {i + 1}: {sample_item}\")"]},{"cell_type":"code","execution_count":74,"id":"d05bad95-b0ce-4183-84c7-b5c5181bfd52","metadata":{},"outputs":[],"source":["# Create a custom collate function\n","def collate_fn(batch):\n","    # Pad sequences within the batch to have equal lengths\n","    padded_batch = pad_sequence(batch, batch_first=True, padding_value=0)\n","    return padded_batch"]},{"cell_type":"code","execution_count":79,"id":"d195b725-3629-4442-8c90-d70e66d8d48f","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[tensor([13, 21, 65, 19, 15,  4,  5, 49,  8, 18, 47,  2, 57,  5, 43, 48, 26, 12,\n","        45, 63, 11, 46,  2, 16, 11, 35,  3]), tensor([37,  8, 18,  5, 40, 42,  2, 10,  3])]\n","['if', 'you', 'want', 'to', 'know', 'what', 'a', 'man', \"'\", 's', 'like', ',', 'take', 'a', 'good', 'look', 'at', 'how', 'he', 'treats', 'his', 'inferiors', ',', 'not', 'his', 'equals', '.']\n","27\n","['fame', \"'\", 's', 'a', 'fickle', 'friend', ',', 'harry', '.', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n","27\n","[tensor([14,  7, 17, 33,  2, 10,  2, 59, 55,  4, 20, 64,  6,  2, 38, 51, 58, 17,\n","        23,  3]), tensor([56, 20, 52, 25, 36, 60, 32, 29,  4,  7, 54,  9,  4,  7, 34,  3])]\n","['it', 'is', 'our', 'choices', ',', 'harry', ',', 'that', 'show', 'what', 'we', 'truly', 'are', ',', 'far', 'more', 'than', 'our', 'abilities', '.']\n","20\n","['soon', 'we', 'must', 'all', 'face', 'the', 'choice', 'between', 'what', 'is', 'right', 'and', 'what', 'is', 'easy', '.', '<unk>', '<unk>', '<unk>', '<unk>']\n","20\n","[tensor([68, 31, 16, 15, 12, 24, 62,  9, 39,  3, 30, 53, 50,  6, 44, 13, 61, 41,\n","         4, 14, 66, 19, 28, 67,  3]), tensor([21,  6, 27, 22])]\n","['youth', 'can', 'not', 'know', 'how', 'age', 'thinks', 'and', 'feels', '.', 'but', 'old', 'men', 'are', 'guilty', 'if', 'they', 'forget', 'what', 'it', 'was', 'to', 'be', 'young', '.']\n","25\n","['you', 'are', 'awesome', '!', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n","25\n"]}],"source":["# Create a data loader with the custom collate function with batch_first=True,\n","dataloader = DataLoader(custom_dataset, batch_size=batch_size, collate_fn=collate_fn)\n","\n","# Iterate through the data loader\n","for batch in dataloader: \n","    for row in batch:\n","        words = [vocab.itos[idx] for idx in row]\n","        print(words)\n","        print(len(words))\n","       "]},{"cell_type":"code","execution_count":59,"id":"6e7e9a3c-3f27-4a35-b09c-a0bb66e724f4","metadata":{},"outputs":[],"source":["# Create a custom collate function\n","def collate_fn_bfFALSE(batch):\n","    # Pad sequences within the batch to have equal lengths\n","    padded_batch = pad_sequence(batch, padding_value=0)\n","    return padded_batch"]},{"cell_type":"markdown","id":"5865557b-08cb-475b-adbc-363e419c1ad2","metadata":{},"source":["Now, you look into the curated data:\n"]},{"cell_type":"code","execution_count":62,"id":"4f38c24c-793f-47f6-8a91-860711c32675","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['if', 'fame']\n","['you', \"'\"]\n","['want', 's']\n","['to', 'a']\n","['know', 'fickle']\n","['what', 'friend']\n","['a', ',']\n","['man', 'harry']\n","[\"'\", '.']\n","['s', '<unk>']\n","['like', '<unk>']\n","[',', '<unk>']\n","['take', '<unk>']\n","['a', '<unk>']\n","['good', '<unk>']\n","['look', '<unk>']\n","['at', '<unk>']\n","['how', '<unk>']\n","['he', '<unk>']\n","['treats', '<unk>']\n","['his', '<unk>']\n","['inferiors', '<unk>']\n","[',', '<unk>']\n","['not', '<unk>']\n","['his', '<unk>']\n","['equals', '<unk>']\n","['.', '<unk>']\n","['it', 'soon']\n","['is', 'we']\n","['our', 'must']\n","['choices', 'all']\n","[',', 'face']\n","['harry', 'the']\n","[',', 'choice']\n","['that', 'between']\n","['show', 'what']\n","['what', 'is']\n","['we', 'right']\n","['truly', 'and']\n","['are', 'what']\n","[',', 'is']\n","['far', 'easy']\n","['more', '.']\n","['than', '<unk>']\n","['our', '<unk>']\n","['abilities', '<unk>']\n","['.', '<unk>']\n","['youth', 'you']\n","['can', 'are']\n","['not', 'awesome']\n","['know', '!']\n","['how', '<unk>']\n","['age', '<unk>']\n","['thinks', '<unk>']\n","['and', '<unk>']\n","['feels', '<unk>']\n","['.', '<unk>']\n","['but', '<unk>']\n","['old', '<unk>']\n","['men', '<unk>']\n","['are', '<unk>']\n","['guilty', '<unk>']\n","['if', '<unk>']\n","['they', '<unk>']\n","['forget', '<unk>']\n","['what', '<unk>']\n","['it', '<unk>']\n","['was', '<unk>']\n","['to', '<unk>']\n","['be', '<unk>']\n","['young', '<unk>']\n","['.', '<unk>']\n"]}],"source":["# Create a data loader with the custom collate function with batch_first=True,\n","dataloader_bfFALSE = DataLoader(custom_dataset, batch_size=batch_size, collate_fn=collate_fn_bfFALSE)\n","\n","# Iterate through the data loader\n","for seq in dataloader_bfFALSE:\n","    for row in seq:\n","        #print(row)\n","        words = [vocab.itos[idx] for idx in row]\n","        print(words)"]},{"cell_type":"code","execution_count":63,"id":"4bb13fd9-b1ea-4aa8-b169-788b818150e3","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[13, 21, 65, 19, 15,  4,  5, 49,  8, 18, 47,  2, 57,  5, 43, 48, 26, 12,\n","         45, 63, 11, 46,  2, 16, 11, 35,  3],\n","        [37,  8, 18,  5, 40, 42,  2, 10,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0,  0,  0,  0,  0,  0]])\n","Length of sequences in the batch: 27\n","tensor([[14,  7, 17, 33,  2, 10,  2, 59, 55,  4, 20, 64,  6,  2, 38, 51, 58, 17,\n","         23,  3],\n","        [56, 20, 52, 25, 36, 60, 32, 29,  4,  7, 54,  9,  4,  7, 34,  3,  0,  0,\n","          0,  0]])\n","Length of sequences in the batch: 20\n","tensor([[68, 31, 16, 15, 12, 24, 62,  9, 39,  3, 30, 53, 50,  6, 44, 13, 61, 41,\n","          4, 14, 66, 19, 28, 67,  3],\n","        [21,  6, 27, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0,  0,  0,  0]])\n","Length of sequences in the batch: 25\n"]}],"source":["# Iterate through the data loader with batch_first = TRUE\n","for batch in dataloader:    \n","    print(batch)\n","    print(\"Length of sequences in the batch:\",batch.shape[1])"]},{"cell_type":"code","execution_count":80,"id":"ffb6c1d1-5262-4a80-a097-5e12fe675def","metadata":{},"outputs":[],"source":["# Define a custom data set\n","class CustomDataset(Dataset):\n","    def __init__(self, sentences):\n","        self.sentences = sentences\n","\n","    def __len__(self):\n","        return len(self.sentences)\n","\n","    def __getitem__(self, idx):\n","        return self.sentences[idx]"]},{"cell_type":"code","execution_count":81,"id":"d5196807-f7c4-4b6a-8b10-b5562aec3574","metadata":{},"outputs":[],"source":["custom_dataset=CustomDataset(sentences)"]},{"cell_type":"code","execution_count":82,"id":"ec21f5e0-c400-4079-aed8-722fdf0ea6d8","metadata":{},"outputs":[{"data":{"text/plain":["\"If you want to know what a man's like, take a good look at how he treats his inferiors, not his equals.\""]},"execution_count":82,"metadata":{},"output_type":"execute_result"}],"source":["custom_dataset[0]"]},{"cell_type":"code","execution_count":86,"id":"fb016dd6-e4a6-45ed-8fee-96039a5f4411","metadata":{},"outputs":[],"source":["def collate_fn(batch):\n","    # Tokenize each sample in the batch using the specified tokenizer\n","    print(batch)\n","    tensor_batch = []\n","    for sample in batch:\n","        tokens = tokenizer(sample)\n","        # Convert tokens to vocabulary indices and create a tensor for each sample\n","        tensor_batch.append(torch.tensor([vocab[token] for token in tokens]))\n","\n","    # Pad sequences within the batch to have equal lengths using pad_sequence\n","    # batch_first=True ensures that the tensors have shape (batch_size, max_sequence_length)\n","    padded_batch = pad_sequence(tensor_batch, batch_first=True)\n","    \n","    # Return the padded batch\n","    return padded_batch"]},{"cell_type":"code","execution_count":87,"id":"779800af-63c1-420a-93a3-70fb1da014c6","metadata":{},"outputs":[],"source":["# Create a data loader for the custom dataset\n","dataloader = DataLoader(\n","    dataset=custom_dataset,   # Custom PyTorch Dataset containing your data\n","    batch_size=batch_size,     # Number of samples in each mini-batch\n","    shuffle=True,              # Shuffle the data at the beginning of each epoch\n","    collate_fn=collate_fn      # Custom collate function for processing batches\n",")"]},{"cell_type":"code","execution_count":88,"id":"02a8d99b-a0ea-4cfd-af19-955233ea1fa0","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['It is our choices, Harry, that show what we truly are, far more than our abilities.', 'You are awesome!']\n","shape of sample 2\n","[\"If you want to know what a man's like, take a good look at how he treats his inferiors, not his equals.\", \"Fame's a fickle friend, Harry.\"]\n","shape of sample 2\n","['Youth can not know how age thinks and feels. But old men are guilty if they forget what it was to be young.', 'Soon we must all face the choice between what is right and what is easy.']\n","shape of sample 2\n"]}],"source":["for batch in dataloader:\n","    # print(batch)\n","    print(\"shape of sample\",len(batch))"]},{"cell_type":"markdown","id":"d703ae51-1c86-4c96-a352-95790e9284b9","metadata":{},"source":["As a result, batches of tensors with equal lengths have been successfully created.\n"]},{"cell_type":"markdown","id":"a84aac6c-5e0e-4390-8707-b765cb754cb4","metadata":{},"source":["## Exercise\n"]},{"cell_type":"markdown","id":"fecf1d2c-c92b-48ff-8596-f91c5143dea6","metadata":{},"source":["Create a data loader with a collate function that processes batches of French text (provided below). Sort the data set on sequences length. Then tokenize, numericalize and pad the sequences. Sorting the sequences will minimize the number of `<PAD>`tokens added to the sequences, which enhances the model's performance. Prepare the data in batches of size 4 and print them.\n"]},{"cell_type":"code","execution_count":97,"id":"001c9be1-4637-418c-8757-fa8a7cd96bb5","metadata":{},"outputs":[],"source":["corpus = [\n","    \"Ceci est une phrase.\",\n","    \"C'est un autre exemple de phrase.\",\n","    \"Voici une troisième phrase.\",\n","    \"Il fait beau aujourd'hui.\",\n","    \"J'aime beaucoup la cuisine française.\",\n","    \"Quel est ton plat préféré ?\",\n","    \"Je t'adore.\",\n","    \"Bon appétit !\",\n","    \"Je suis en train d'apprendre le français.\",\n","    \"Nous devons partir tôt demain matin.\",\n","    \"Je suis heureux.\",\n","    \"Le film était vraiment captivant !\",\n","    \"Je suis là.\",\n","    \"Je ne sais pas.\",\n","    \"Je suis fatigué après une longue journée de travail.\",\n","    \"Est-ce que tu as des projets pour le week-end ?\",\n","    \"Je vais chez le médecin cet après-midi.\",\n","    \"La musique adoucit les mœurs.\",\n","    \"Je dois acheter du pain et du lait.\",\n","    \"Il y a beaucoup de monde dans cette ville.\",\n","    \"Merci beaucoup !\",\n","    \"Au revoir !\",\n","    \"Je suis ravi de vous rencontrer enfin !\",\n","    \"Les vacances sont toujours trop courtes.\",\n","    \"Je suis en retard.\",\n","    \"Félicitations pour ton nouveau travail !\",\n","    \"Je suis désolé, je ne peux pas venir à la réunion.\",\n","    \"À quelle heure est le prochain train ?\",\n","    \"Bonjour !\",\n","    \"C'est génial !\"\n","]"]},{"cell_type":"code","execution_count":98,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["30lines [00:00, 31528.22lines/s]\n"]}],"source":["def collate_fn_fr(batch):\n","    # Pad sequences within the batch to have equal lengths\n","    tensor_batch=[]\n","    for sample in batch:\n","        tokens = tokenizer(sample)\n","        tensor_batch.append(torch.tensor([vocab[token] for token in tokens]))\n","         \n","    padded_batch = pad_sequence(tensor_batch,batch_first=True)\n","    return padded_batch\n","\n","# Build tokenizer\n","tokenizer = get_tokenizer('basic_english')\n","\n","# Build vocabulary\n","vocab = build_vocab_from_iterator(map(tokenizer, corpus))\n","\n","# Sort sentences based on their length\n","sorted_data = sorted(corpus, key=lambda x: len(tokenizer(x)))\n","#print(sorted_data)\n","dataloader = DataLoader(sorted_data, batch_size=4, shuffle=False, collate_fn=collate_fn_fr)"]},{"cell_type":"code","execution_count":99,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[43,  4,  0],\n","        [42, 34,  4],\n","        [78, 11,  4],\n","        [38, 98,  4]])\n","tensor([[  3,   5,  70,   2,   0],\n","        [  3,   5,  76,   2,   0],\n","        [ 45,   7,  14,  13,   2],\n","        [113,  14, 104,  13,   2]])\n","tensor([[  3, 102,   6,  30,   2],\n","        [  3,  20, 100,  21,   2],\n","        [  3,   5,  17,  97,   2],\n","        [ 15,   6,   7,  68,   4]])\n","tensor([[ 93,   7,  23,  88,  91,  10],\n","        [  8,  64, 118, 115,  44,   4],\n","        [ 12,  80,  31,  19,  82,   2],\n","        [ 67,  22,  23,  84,  25,   4]])\n","tensor([[ 18,  62,  41,  39,   6,  71,   2,   0],\n","        [ 83,  55,  86, 107,  53,  77,   2,   0],\n","        [ 19, 109, 101, 103, 105,  49,   2,   0],\n","        [ 72,   6,  32,  11,  12,  50,  66,   2]])\n","tensor([[  3, 110,  48,   8,  81,  46,  36,   2,   0],\n","        [  3,   5,  95,   9, 114,  96,  58,   4,   0],\n","        [ 26,  94,  69,   7,   8,  89,  24,  10,   0],\n","        [ 15,   6,   7, 108,  40,  61,   9,  13,   2]])\n","tensor([[  3,  56,  29,  16,  85,  60,  16,  74,   2,   0],\n","        [  3,   5,  17,  24,  51,   6,  33,   8,  65,   2],\n","        [  3,   5,  63,  35,  14,  75,  73,   9,  25,   2],\n","        [ 59,  92, 106,  37,  54,  90,  22,   8, 116,  10]])\n","tensor([[ 18, 117,  28,  11,   9,  79,  52,  47, 112,   2,   0,   0,   0],\n","        [  3,   5,  57,  27,   3,  20,  87,  21, 111,  26,  12,  99,   2]])\n"]}],"source":["for batch in dataloader:\n","    print(batch)"]},{"cell_type":"code","execution_count":105,"id":"f5c0a728-d757-49d7-82ca-8d3e66e141a2","metadata":{},"outputs":[{"ename":"ImportError","evalue":"cannot import name 'multi30k' from 'torchtext.datasets' (c:\\Users\\vishwas.balkundi\\miniforge3\\envs\\myenv2\\Lib\\site-packages\\torchtext\\datasets\\__init__.py)","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[1;32mIn[105], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multi30k,Multi30k\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Multi30k[\"train\"] = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0205EN-SkillsNetwork/training.tar.gz\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Multi30k[\"valid\"] = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0205EN-SkillsNetwork/validation.tar.gz\"\u001b[39;00m\n","\u001b[1;31mImportError\u001b[0m: cannot import name 'multi30k' from 'torchtext.datasets' (c:\\Users\\vishwas.balkundi\\miniforge3\\envs\\myenv2\\Lib\\site-packages\\torchtext\\datasets\\__init__.py)"]}],"source":["from torchtext.datasets import multi30k,Multi30k\n","# Multi30k[\"train\"] = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0205EN-SkillsNetwork/training.tar.gz\"\n","# Multi30k[\"valid\"] = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0205EN-SkillsNetwork/validation.tar.gz\""]},{"cell_type":"code","execution_count":null,"id":"5132bb91-d740-4b64-991f-73cbadf818b6","metadata":{},"outputs":[],"source":["SRC_LANGUAGE = 'de'\n","TGT_LANGUAGE = 'en'"]},{"cell_type":"code","execution_count":null,"id":"6d042b54-4cc6-4e47-b22c-4eafe076db52","metadata":{},"outputs":[],"source":["train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))"]},{"cell_type":"code","execution_count":null,"id":"d01fac70-80d2-4658-b1af-6e40bcae8171","metadata":{},"outputs":[],"source":["data_set = iter(train_iter)"]},{"cell_type":"code","execution_count":null,"id":"bdfa4d5a-a736-4a7b-870b-4b97e4492125","metadata":{},"outputs":[],"source":["for n in range(5):\n","    # Getting the next pair of source and target sentences from the training data set\n","    src, tgt = next(data_set)\n","\n","    # Printing the source (German) and target (English) sentences\n","    print(f\"sample {str(n+1)}\")\n","    print(f\"Source ({SRC_LANGUAGE}): {src}\\nTarget ({TGT_LANGUAGE}): {tgt}\")"]},{"cell_type":"code","execution_count":null,"id":"f72b60c9-f7c6-49e2-b94b-5c21da782505","metadata":{},"outputs":[],"source":["german, english = next(data_set)\n","print(f\"Source German ({SRC_LANGUAGE}): {german}\\nTarget English  ({TGT_LANGUAGE}): { english }\")"]},{"cell_type":"code","execution_count":null,"id":"d023955e-041a-4e32-9aa6-8a2d92170e02","metadata":{},"outputs":[],"source":["from torchtext.data.utils import get_tokenizer"]},{"cell_type":"code","execution_count":null,"id":"c78a1246-21a7-4b07-b217-0ed84e2a5d17","metadata":{},"outputs":[],"source":["# Making a placeholder dict to store both tokenizers\n","token_transform = {}\n","\n","token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='de_core_news_sm')\n","token_transform[TGT_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')"]},{"cell_type":"code","execution_count":null,"id":"5a497800-e1a8-49b6-9b6f-8d417c046607","metadata":{},"outputs":[],"source":["token_transform['de'](german)"]},{"cell_type":"code","execution_count":null,"id":"7a2591ca-4395-4a33-837c-dfa0808509f1","metadata":{},"outputs":[],"source":["token_transform['en'](english)"]},{"cell_type":"code","execution_count":null,"id":"448a53ad-b770-4f15-8698-4f1f4515b728","metadata":{},"outputs":[],"source":["# Define special symbols and indices\n","UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n","# Make sure the tokens are in order of their indices to properly insert them in vocab\n","special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']"]},{"cell_type":"code","execution_count":null,"id":"c6716a96-17e8-4540-9d30-c4f4b9f6a159","metadata":{},"outputs":[],"source":["#place holder dict for 'en' and 'de' vocab transforms\n","vocab_transform = {}"]},{"cell_type":"code","execution_count":null,"id":"23d2fbb5-78d0-405e-b9d4-dba3e614edd4","metadata":{},"outputs":[],"source":["def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n","    # Define a mapping to associate the source and target languages\n","    # with their respective positions in the data samples.\n","    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n","\n","    # Iterate over each data sample in the provided dataset iterator\n","    for data_sample in data_iter:\n","        # Tokenize the data sample corresponding to the specified language\n","        # and yield the resulting tokens.\n","        yield token_transform[language](data_sample[language_index[language]])"]},{"cell_type":"code","execution_count":null,"id":"c6de909f-200b-4729-a946-6db5f98c5aea","metadata":{},"outputs":[],"source":["for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n","    # Training data iterator\n","    train_iterator = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n","    #To decrease the number of padding tokens, you sort data on the source length to batch similar-length sequences together\n","    sorted_dataset = sorted(train_iterator, key=lambda x: len(x[0].split()))\n","    # Create torchtext's Vocab object\n","    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(sorted_dataset, ln),\n","                                                    min_freq=1,\n","                                                    specials=special_symbols,\n","                                                    special_first=True)"]},{"cell_type":"code","execution_count":null,"id":"6162114d-4b3e-4c51-a062-2eb06523102a","metadata":{},"outputs":[],"source":["# If not set, it throws ``RuntimeError`` when the queried token is not found in the Vocabulary.\n","for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n","  vocab_transform[ln].set_default_index(UNK_IDX)"]},{"cell_type":"code","execution_count":null,"id":"e1e02c57-807c-40d3-85da-bf3e6a66a4d6","metadata":{},"outputs":[],"source":["seq_en=vocab_transform['en'](token_transform['en'](english))\n","print(f\"English text string: {english}\\n English sequence: {seq_en}\")\n","\n","seq_de=vocab_transform['de'](token_transform['de'](german))\n","print(f\"German text string: {german}\\n German sequence: {seq_de}\")\n"]},{"cell_type":"code","execution_count":null,"id":"f5185e0a-d4c3-418f-8a8c-661d21ac9a54","metadata":{},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":null,"id":"7afe60ee-be57-4a28-a2c6-355e47fb4b4e","metadata":{},"outputs":[],"source":["# function to add BOS/EOS, flip source sentence and create tensor for input sequence indices\n","def tensor_transform_s(token_ids: List[int]):\n","    return torch.cat((torch.tensor([BOS_IDX]),\n","                      torch.flip(torch.tensor(token_ids), dims=(0,)),\n","                      torch.tensor([EOS_IDX])))\n","\n","# function to add BOS/EOS and create tensor for input sequence indices\n","def tensor_transform_t(token_ids: List[int]):\n","    return torch.cat((torch.tensor([BOS_IDX]),\n","                      torch.tensor(token_ids),\n","                      torch.tensor([EOS_IDX])))"]},{"cell_type":"code","execution_count":null,"id":"d7714d9a-0d1c-4e13-95dc-83fd3cb4b0e2","metadata":{},"outputs":[],"source":["seq_en=tensor_transform_s(seq_en)\n","seq_en"]},{"cell_type":"code","execution_count":null,"id":"b362e0e5-1d55-4aea-b6f8-78ae9ab28d33","metadata":{},"outputs":[],"source":["seq_de=tensor_transform_t(seq_de)\n","seq_de"]},{"cell_type":"code","execution_count":null,"id":"10b755dd-7b61-4a19-9641-6ec5a4711fb7","metadata":{},"outputs":[],"source":["# helper function to club together sequential operations\n","def sequential_transforms(*transforms):\n","    def func(txt_input):\n","        for transform in transforms:\n","            txt_input = transform(txt_input)\n","        return txt_input\n","    return func\n","\n","# ``src`` and ``tgt`` language text transforms to convert raw strings into tensors indices\n","text_transform = {}\n","\n","text_transform[SRC_LANGUAGE] = sequential_transforms(token_transform[SRC_LANGUAGE], #Tokenization\n","                                            vocab_transform[SRC_LANGUAGE], #Numericalization\n","                                            tensor_transform_s) # Add BOS/EOS and create tensor\n","\n","text_transform[TGT_LANGUAGE] = sequential_transforms(token_transform[TGT_LANGUAGE], #Tokenization\n","                                            vocab_transform[TGT_LANGUAGE], #Numericalization\n","                                            tensor_transform_t) # Add BOS/EOS and create tensor\n"]},{"cell_type":"code","execution_count":null,"id":"8010ab2d-1c43-4cfe-aec2-2134354a893b","metadata":{},"outputs":[],"source":["# function to collate data samples into batch tensors\n","def collate_fn(batch):\n","    src_batch, tgt_batch = [], []\n","    for src_sample, tgt_sample in batch:\n","        src_sequences = text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\"))\n","        src_sequences = torch.tensor(src_sequences, dtype=torch.int64)\n","        tgt_sequences = text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\"))\n","        tgt_sequences = torch.tensor(tgt_sequences, dtype=torch.int64)\n","        src_batch.append(src_sequences)\n","        tgt_batch.append(tgt_sequences)\n","\n","    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX,batch_first=True)\n","    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX,batch_first=True)\n","    \n","    return src_batch.to(device), tgt_batch.to(device)\n"]},{"cell_type":"code","execution_count":null,"id":"81c58104-af75-4865-a229-1bc059cc6b25","metadata":{},"outputs":[],"source":["BATCH_SIZE = 4\n","\n","train_iterator = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n","sorted_train_iterator = sorted(train_iterator, key=lambda x: len(x[0].split()))\n","train_dataloader = DataLoader(sorted_train_iterator, batch_size=BATCH_SIZE, collate_fn=collate_fn,drop_last=True)\n","\n","valid_iterator = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n","sorted_valid_dataloader = sorted(valid_iterator, key=lambda x: len(x[0].split()))\n","valid_dataloader = DataLoader(sorted_valid_dataloader, batch_size=BATCH_SIZE, collate_fn=collate_fn,drop_last=True)\n","\n","\n","src, trg = next(iter(train_dataloader))\n","src,trg"]},{"cell_type":"markdown","id":"a9822b66-03f6-4b7c-a485-de04c79dceba","metadata":{},"source":["```{## Change Log}\n","```\n"]},{"cell_type":"markdown","id":"6a1e59b3-f74f-4435-bf58-2c1a596dfdac","metadata":{},"source":["```{|Date (YYYY-MM-DD)|Version|Changed By|Change Description|}\n","```\n","```{|-|-|-|-|}\n","```\n","```{|2023-10-24|0.1|Roodra|Created Lab Template|}\n","```\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.5"},"prev_pub_hash":"8c22317e777527276102edc9a5fee16b619deefd7fe94e10f36fb454230c542e"},"nbformat":4,"nbformat_minor":4}
